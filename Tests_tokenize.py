from nltk.tokenize import TreebankWordTokenizer

text = "Етӕ ’нцӕ Донбеттири кизгуттӕ, уонӕй ку фӕццӕф кодтай. И дуккаг бон ба Нартӕ рамбурд ӕнцӕ Тъизмуди уӕлеуати бунмӕ’ма синдбӕл исхуӕстӕнцӕ."
words = TreebankWordTokenizer().tokenize(text, convert_parentheses=True)
print(words)
#1 ['Етӕ', '’', 'нцӕ', 'Донбеттири', 'кизгуттӕ', ',', 'уонӕй', 'ку', 'фӕццӕф', 'кодтай', '.', 'И', 'дуккаг', 'бон', 'ба', 'Нартӕ', 'рамбурд', 'ӕнцӕ', 'Тъизмуди', 'уӕлеуати', 'бунмӕ', '’', 'ма', 'синдбӕл', 'исхуӕстӕнцӕ', '.']
